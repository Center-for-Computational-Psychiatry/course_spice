{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://colab.research.google.com/github/center-for-computational-psychiatry/course_spice/blob/master/modules/module-04_data-processing.ipynb\">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</a>\n",
    "\n",
    "# Data Processing\n",
    "This tutorial was inspired by and adapted from Shawn A. Rhoads' [PSYC 347 Course](https://shawnrhoads.github.io/gu-psyc-347/) [[CC BY-SA 4.0 License](https://creativecommons.org/licenses/by-sa/4.0/)].\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "This notebook is intended to teach you basic python syntax for:\n",
    "\n",
    "1. Reading data from a file\n",
    "2. Summarizing data\n",
    "3. Filtering data\n",
    "4. Writing data to a file\n",
    "\n",
    "One important package will be used in this notebook: `pandas`. Pandas is a powerful data analysis package. It is designed to make data analysis fast and easy in Python. It is also designed to work with data in a tabular format, which is a common way to store data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to work with open data from Sarah's 2022 paper: \n",
    "\n",
    "<blockquote>Banker, S. M., Na, S., Beltr√°n, J., Koenigsberg, H. W., Foss-Feig, J. H., Gu, X., & Schiller, D. (2022). Disrupted computations of social control in individuals with obsessive-compulsive and misophonia symptoms. iScience, 25(7), 104617. https://doi.org/10.1016/j.isci.2022.104617</blockquote>\n",
    "\n",
    "The data is available on [OSF](https://osf.io/ad7np/). I already cleaned it up a little bit. We will be using the `Banker_et_al_2022_QuestionnaireData.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/Center-for-Computational-Psychiatry/course_spice/main/modules/resources/data/Banker_et_al_2022_QuestionnaireData.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read this file, we will use the `pandas` package. `pandas` is a Python library used for data manipulation and analysis. It provides data structures for efficiently storing and manipulating large datasets, as well as tools for working with data from a variety of sources such as CSV files, SQL databases, and Excel spreadsheets. Pandas is commonly used in data science and machine learning applications, as well as in finance, social science, and other fields where data analysis is important.\n",
    "\n",
    "A CSV file is a comma-separated values file, which allows data to be saved in a tabular format. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. CSV files can be opened in spreadsheet applications like Microsoft Excel or Google Sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import pandas using the alias pd\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we imported `pandas` using the `import` statement. This statement makes the `pandas` package available to us in our notebook. We will use `import` to make other packages available to us as well throughout this course and in your research.\n",
    "\n",
    "We can now use the functions and data structures provided by `pandas` in our code. We will use the `pandas` package to read in the data from the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in the data from the CSV file. We will use the `read_csv()` function from the `pandas` package to do this. The `read_csv()` function takes a single argument, the path to the CSV file to read. The function returns a `DataFrame` object, which is a data structure provided by `pandas` for storing tabular data. We will assign the `DataFrame` object returned by `read_csv()` to a variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of your DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preview the first five rows of the `DataFrame` using the `head()` method. The `head()` method takes a single argument, the number of rows to preview. If no argument is provided, the `head()` method will return the first five rows by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(our_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that we have a lot of columns in this `DataFrame`. We can use the `shape` attribute to see the dimensions of the `DataFrame`. The `shape` attribute returns a tuple containing the number of rows and columns in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1175 rows and 21 columns. Typically, the rows in a `DataFrame` represent observations and the columns represent variables. In this case, each row represents a participant and each column represents a variable measured for each participant.\n",
    "\n",
    "To get a better sense of our variables, we can use the `info()` method. The `info()` method prints a summary of the `DataFrame` including the number of rows and columns, the number of non-null values in each column, and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(our_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice a few key things from the output of the `info()` method. First, we have 1175 rows and 21 columns, which matches the output of the `shape` attribute. Second, we have 1175 non-null values in each column, which means that we have no missing data. Third, we have a mix of data types. Most of the columns contain integers, but some of the columns contain floating point numbers and some of the columns contain strings (objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list out all of the columns in the `DataFrame` using the `columns` attribute. The `columns` attribute returns a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(our_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring variables within your DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore some of our variables. We can start with 'Age'. We can use the `describe()` method to get summary statistics for a column. The `describe()` method takes a single argument, the name of the column to summarize. The `describe()` method returns a `Series` object, which is a data structure provided by `pandas` for storing a single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean age of our participants is 35.88 years old. The youngest participant is 18 years old and the oldest participant is 77 years old. The standard deviation is 13.35 years. This seems like a pretty young sample in terms of age! I would typically plot these data to get a better sense of the distribution of ages, but we will save that for the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `describe()` to get summary statistics for other columns as well. For example, we can use `describe()` to get summary statistics for the 'Subjective Happiness' column, which contains the total score on Subjective Happiness Scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data['Subjective Happiness'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean score of our participants is 17.64 -- our sample is pretty happy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data that are rank-ordered, such as \"Income\" or \"Education\", computing the mean and standard deviation is not very informative. Instead, we can use the `value_counts()` method to get a frequency count for each value in the column. The `value_counts()` method takes a single argument, the name of the column to summarize. The `value_counts()` method returns a `Series` object, which is a data structure provided by `pandas` for storing a single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data['Income'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see a table of frequencies for each rank (ranging from 1 to 12). You should notice that there seem to be many more participants who have lower ranks (e.g., 3, 4, 5) than higher ranks (e.g., 10, 12). This is a common pattern for rank-ordered income data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new variables \n",
    "\n",
    "#### Can money buy happiness?\n",
    "\n",
    "Let's explore the relationship between income and happiness. To do this, let's split participants into different income brackets. We will create a new column called 'IncomeSplit' that contains the string 'High' if the participant's income rank is in the top 33.3%, 'Medium' if the participant's income rank is in the middle 33.3%, and 'Low' if the participant's income rank is in the bottom 33.3%.\n",
    "\n",
    "is greater than or equal to the median income rank and 'Low' if the participant's income rank is less than the median income rank.\n",
    "\n",
    "We can use the `qcut()` function to perform the a quantitle split. The `qcut()` function takes three arguments: the `DataFrame` to split, the name of the column to split, and the number of bins to split the data into. The `qcut()` function returns a `Series` object, which is a data structure provided by `pandas` for storing a single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data['IncomeSplit'] = pd.qcut(our_data['Income'], q=3, labels=['Low','Medium','High']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created a new column called \"IncomeSplit\". We can see it now in our columns (all the way at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(our_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our new variable, we can view the frequency counts for each level of the variable using the `value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data['IncomeSplit'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `groupby()` method to group the data by the 'IncomeSplit' column. The `groupby()` method takes a single argument, the name of the column to group by. The `groupby()` method returns a `DataFrameGroupBy` object, which is a data structure provided by `pandas` for storing grouped data.\n",
    "\n",
    "We will again use the `describe()` method to get summary statistics for the 'Subjective Happiness' column, grouped by the 'IncomeSplit' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data.groupby('IncomeSplit')['Subjective Happiness'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effects is small, but it looks like participants mean happiness scores increase as the income bracket group goes from \"Low\" to \"High\"!\n",
    "\n",
    "Remember, **it is important to think critically about your variables**. Income is associated with many different factors (e.g., access to healthcare, access to education, job security, etc.), so it makes sense if people with more resources report being happier (or if people who report being happier have greater incomes -- remember correlation does not imply causation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "Now that have a sense of our data, let's filter it down to a subset of participants. We can use the `query()` method to do this. The `query()` method takes a single argument, a string containing a boolean expression. The `query()` method returns a `DataFrame` object containing only the rows that match the boolean expression.\n",
    "\n",
    "One variable in particular is the \"Attention Check\" column, which indicates if a participant missed an attention check question. We can use the `query()` method to filter out participants who missed an attention check question. We can do this by querying the 'attention_sum' column to see if it is equal to 0. We can then assign the filtered `DataFrame` to a new variable called `our_data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data_clean = our_data.query(\"AttentionCheck == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our new `DataFrame` contains 1090 rows (which is 85 fewer rows than our original `DataFrame`). This means that 85 participants missed an attention check question! We should exclude these participants from future analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how \"Age\" and \"Subjective Happiness\" changed for this filtered sample. Let's do this in a for-loop this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name in ['Age','Subjective Happiness']:\n",
    "    print(our_data_clean[var_name].describe(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much has drastically changed! This is good news -- it means that the participants who missed an attention check question are not very different from the participants who did not miss an attention check question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your filtered data\n",
    "\n",
    "To save our filtered data, we can use the `to_csv()` method. The `to_csv()` method takes a single argument, the name of the file to save the `DataFrame` to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data_clean.to_csv('./resources/data/Banker_et_al_2022_QuestionnaireData_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now, using our filtered dataframe, try this for any other variables you are interested in! Pick one! For example, you can look at the descriptive statistics for any of the psychiatric variables and group them by various demographic variables.\n",
    "\n",
    "Carry out the following tasks:\n",
    "1. Pick one of the psychiatric variables (e.g., \"Depression\", \"Stress\", \"Social Anxiety\")\n",
    "2. Use the `describe()` method to get summary statistics for that variable.\n",
    "3. Pick a second variable and create a new column based on the median split (hint: you can change `q=3` to `q=2` and `labels=[\"Low\",\"Medium\",\"High\"]` to `labels=[\"Low\",\"High\"]` in the `pd.qcut()` function).\n",
    "4. Summarize the psychiatric variable by the new column you created in step 3 using the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
